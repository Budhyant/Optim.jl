<!DOCTYPE html>
<html lang="en">
<head>
  
  
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    <meta name="author" content="JuliaNLSolvers">
    
    <link rel="shortcut icon" href="../../img/favicon.ico">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" />
    <title>Tips and tricks - Optim.jl</title>
    <link href="../../css/bootstrap-3.3.7.min.css" rel="stylesheet">
    <link href="../../css/font-awesome-4.7.0.css" rel="stylesheet">
    <link href="../../css/base.css" rel="stylesheet">
    <link rel="stylesheet" href="../../css/highlight.css">
    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
    <![endif]-->

    <script src="../../js/jquery-3.2.1.min.js"></script>
    <script src="../../js/bootstrap-3.3.7.min.js"></script>
    <script src="../../js/highlight.pack.js"></script>
    
    <base target="_top">
    <script>
      var base_url = '../..';
      var is_top_frame = false;
        
        var pageToc = [
          {title: "Dealing with constant parameters", url: "#dealing-with-constant-parameters", children: [
          ]},
          {title: "Avoid repeating computations", url: "#avoid-repeating-computations", children: [
          ]},
          {title: "Provide gradients", url: "#provide-gradients", children: [
          ]},
          {title: "Separating time spent in Optim's code and user provided functions", url: "#separating-time-spent-in-optims-code-and-user-provided-functions", children: [
          ]},
          {title: "Early stopping", url: "#early-stopping", children: [
          ]},
        ];

    </script>
    <script src="../../js/base.js"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_HTML"></script>
      <script src="../../assets/mathjaxhelper.js"></script>
      <script src="../../search/require.js"></script>
      <script src="../../search/search.js"></script> 
</head>

<body>
<script>
if (is_top_frame) { $('body').addClass('wm-top-page'); }
</script>



<div class="container-fluid wm-page-content">
    

  <div class="row wm-article-nav-buttons" role="navigation" aria-label="navigation">
    
    <div class="wm-article-nav pull-right">
      <a href="../../algo/nelder_mead/" class="btn btn-xs btn-default pull-right">
        Next
        <i class="fa fa-chevron-right" aria-hidden="true"></i>
      </a>
      <a href="../../algo/nelder_mead/" class="btn btn-xs btn-link">
        Nelder Mead
      </a>
    </div>
    
    <div class="wm-article-nav">
      <a href="../config/" class="btn btn-xs btn-default pull-left">
        <i class="fa fa-chevron-left" aria-hidden="true"></i>
        Previous</a><a href="../config/" class="btn btn-xs btn-link">
        Configurable Options
      </a>
    </div>
    
  </div>

    

    <p><a id='Dealing-with-constant-parameters-1'></a></p>
<h2 id="dealing-with-constant-parameters">Dealing with constant parameters</h2>
<p>In many applications, there may be factors that are relevant to the function evaluations, but are fixed throughout the optimization. An obvious example is using data in a likelihood function, but it could also be parameters we wish to hold constant.</p>
<p>Consider a squared error loss function that depends on some data <code>x</code> and <code>y</code>, and parameters <code>betas</code>. As far as the solver is concerned, there should only be one input argument to the function we want to minimize, call it <code>sqerror</code>.</p>
<p>The problem is that we want to optimize a function <code>sqerror</code> that really depends on three inputs, and two of them are constant throught the optimization procedure. To do this, we need to define the variables <code>x</code> and <code>y</code></p>
<div class="codehilite"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">+</span> <span class="mf">2.0</span> <span class="o">*</span> <span class="n">x</span> <span class="o">+</span> <span class="p">[</span><span class="o">-</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1</span><span class="p">]</span>
</pre></div>


<p>We then simply define a function in three variables</p>
<div class="codehilite"><pre><span></span><span class="k">function</span> <span class="n">sqerror</span><span class="p">(</span><span class="n">betas</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>
    <span class="n">err</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="k">for</span> <span class="n">i</span> <span class="kp">in</span> <span class="mi">1</span><span class="o">:</span><span class="n">length</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">pred_i</span> <span class="o">=</span> <span class="n">betas</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">betas</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">*</span> <span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">err</span> <span class="o">+=</span> <span class="p">(</span><span class="n">Y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">pred_i</span><span class="p">)</span><span class="o">^</span><span class="mi">2</span>
    <span class="k">end</span>
    <span class="k">return</span> <span class="n">err</span>
<span class="k">end</span>
</pre></div>


<p>and then optimize the following anonymous function</p>
<div class="codehilite"><pre><span></span><span class="n">res</span> <span class="o">=</span> <span class="n">optimize</span><span class="p">(</span><span class="n">b</span> <span class="o">-&gt;</span> <span class="n">sqerror</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">),</span> <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">])</span>
</pre></div>


<p>Alternatively, we can define a closure <code>sqerror(betas)</code> that is aware of the variables we just defined</p>
<div class="codehilite"><pre><span></span><span class="k">function</span> <span class="n">sqerror</span><span class="p">(</span><span class="n">betas</span><span class="p">)</span>
    <span class="n">err</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="k">for</span> <span class="n">i</span> <span class="kp">in</span> <span class="mi">1</span><span class="o">:</span><span class="n">length</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">pred_i</span> <span class="o">=</span> <span class="n">betas</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">betas</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">err</span> <span class="o">+=</span> <span class="p">(</span><span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">pred_i</span><span class="p">)</span><span class="o">^</span><span class="mi">2</span>
    <span class="k">end</span>
    <span class="k">return</span> <span class="n">err</span>
<span class="k">end</span>
</pre></div>


<p>We can then optimize the <code>sqerror</code> function just like any other function</p>
<div class="codehilite"><pre><span></span><span class="n">res</span> <span class="o">=</span> <span class="n">optimize</span><span class="p">(</span><span class="n">sqerror</span><span class="p">,</span> <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">])</span>
</pre></div>


<p><a id='Avoid-repeating-computations-1'></a></p>
<h2 id="avoid-repeating-computations">Avoid repeating computations</h2>
<p>Say you are optimizing a function</p>
<div class="codehilite"><pre><span></span><span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">^</span><span class="mi">2</span><span class="o">+</span><span class="n">x</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">^</span><span class="mi">2</span>
<span class="n">g!</span><span class="p">(</span><span class="n">storage</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span> <span class="o">=</span> <span class="n">copy!</span><span class="p">(</span><span class="n">storage</span><span class="p">,</span> <span class="p">[</span><span class="mi">2</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">2</span><span class="n">x</span><span class="p">[</span><span class="mi">2</span><span class="p">]])</span>
</pre></div>


<p>In this situation, no calculations from <code>f</code> could be reused in <code>g!</code>. However, sometimes there is a substantial similarity between the objective function, and gradient, and some calculations can be reused. The trick here is essentially the same as above. We use a closure or an anonymous function. Basically, we define</p>
<div class="codehilite"><pre><span></span><span class="k">function</span> <span class="n">calculate_common!</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">last_x</span><span class="p">,</span> <span class="n">buffer</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">x</span> <span class="o">!=</span> <span class="n">last_x</span>
        <span class="n">copy!</span><span class="p">(</span><span class="n">last_x</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
        <span class="c">#do whatever common calculations and save to buffer</span>
    <span class="k">end</span>
<span class="k">end</span>

<span class="k">function</span> <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">buffer</span><span class="p">,</span> <span class="n">last_x</span><span class="p">)</span>
    <span class="n">calculate_common!</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">last_x</span><span class="p">,</span> <span class="n">buffer</span><span class="p">)</span>
    <span class="n">f_body</span> <span class="c"># depends on buffer</span>
<span class="k">end</span>

<span class="k">function</span> <span class="n">g!</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">stor</span><span class="p">,</span> <span class="n">buffer</span><span class="p">,</span> <span class="n">last_x</span><span class="p">)</span>
    <span class="n">calculate_common!</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">last_x</span><span class="p">,</span> <span class="n">buffer</span><span class="p">)</span>
    <span class="n">g_body!</span> <span class="c"># depends on buffer</span>
<span class="k">end</span>
</pre></div>


<p>and then the following</p>
<div class="codehilite"><pre><span></span><span class="k">using</span> <span class="n">Optim</span>
<span class="n">initial_x</span> <span class="o">=</span> <span class="o">...</span>
<span class="n">buffer</span> <span class="o">=</span> <span class="kt">Array</span><span class="p">{</span><span class="n">eltype</span><span class="p">(</span><span class="n">initial_x</span><span class="p">)}(</span><span class="o">...</span><span class="p">)</span> <span class="c"># Preallocate an appropriate buffer</span>
<span class="n">last_x</span> <span class="o">=</span> <span class="n">similar</span><span class="p">(</span><span class="n">initial_x</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">TwiceDifferentiable</span><span class="p">(</span><span class="n">x</span> <span class="o">-&gt;</span> <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">buffer</span><span class="p">,</span> <span class="n">initial_x</span><span class="p">),</span>
                                <span class="p">(</span><span class="n">stor</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">g!</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">stor</span><span class="p">,</span> <span class="n">buffer</span><span class="p">,</span> <span class="n">last_x</span><span class="p">))</span>
<span class="n">optimize</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">initial_x</span><span class="p">)</span>
</pre></div>


<p><a id='Provide-gradients-1'></a></p>
<h2 id="provide-gradients">Provide gradients</h2>
<p>As mentioned in the general introduction, passing analytical gradients can have an impact on performance. To show an example of this, consider the separable extension of the Rosenbrock function in dimension 5000, see <a href="ftp://ftp.numerical.rl.ac.uk/pub/cutest/sif/SROSENBR.SIF">SROSENBR</a> in CUTEst.</p>
<p>Below, we use the gradients and objective functions from <a href="http://www.cuter.rl.ac.uk/Problems/mastsif.shtml">mastsif</a> through <a href="https://github.com/JuliaSmoothOptimizers/CUTEst.jl">CUTEst.jl</a>. We only show the first five iterations of an attempt to minimize the function using Gradient Descent.</p>
<div class="codehilite"><pre><span></span><span class="gp">julia&gt;</span> <span class="nd">@time</span> <span class="n">optimize</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">initial_x</span><span class="p">,</span> <span class="n">GradientDescent</span><span class="p">(),</span>
                      <span class="n">Optim</span><span class="o">.</span><span class="n">Options</span><span class="p">(</span><span class="n">show_trace</span><span class="o">=</span><span class="kc">true</span><span class="p">,</span> <span class="n">iterations</span> <span class="o">=</span> <span class="mi">5</span><span class="p">))</span>
<span class="go">Iter     Function value   Gradient norm</span>
<span class="go">     0     4.850000e+04     2.116000e+02</span>
<span class="go">     1     1.018734e+03     2.704951e+01</span>
<span class="go">     2     3.468449e+00     5.721261e-01</span>
<span class="go">     3     2.966899e+00     2.638790e-02</span>
<span class="go">     4     2.511859e+00     5.237768e-01</span>
<span class="go">     5     2.107853e+00     1.020287e-01</span>
<span class="go"> 21.731129 seconds (1.61 M allocations: 63.434 MB, 0.03% gc time)</span>
<span class="go">Results of Optimization Algorithm</span>
<span class="go"> * Algorithm: Gradient Descent</span>
<span class="go"> * Starting Point: [1.2,1.0, ...]</span>
<span class="go"> * Minimizer: [1.0287767703731154,1.058769439356144, ...]</span>
<span class="go"> * Minimum: 2.107853e+00</span>
<span class="go"> * Iterations: 5</span>
<span class="go"> * Convergence: false</span>
<span class="go">   * |x - x&#39;| &lt; 0.0: false</span>
<span class="go">   * |f(x) - f(x&#39;)| / |f(x)| &lt; 0.0: false</span>
<span class="go">   * |g(x)| &lt; 1.0e-08: false</span>
<span class="go">   * Reached Maximum Number of Iterations: true</span>
<span class="go"> * Objective Function Calls: 23</span>
<span class="go"> * Gradient Calls: 23</span>

<span class="gp">julia&gt;</span> <span class="nd">@time</span> <span class="n">optimize</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">g!</span><span class="p">,</span> <span class="n">initial_x</span><span class="p">,</span> <span class="n">GradientDescent</span><span class="p">(),</span>
                      <span class="n">Optim</span><span class="o">.</span><span class="n">Options</span><span class="p">(</span><span class="n">show_trace</span><span class="o">=</span><span class="kc">true</span><span class="p">,</span> <span class="n">iterations</span> <span class="o">=</span> <span class="mi">5</span><span class="p">))</span>
<span class="go">Iter     Function value   Gradient norm</span>
<span class="go">     0     4.850000e+04     2.116000e+02</span>
<span class="go">     1     1.018769e+03     2.704998e+01</span>
<span class="go">     2     3.468488e+00     5.721481e-01</span>
<span class="go">     3     2.966900e+00     2.638792e-02</span>
<span class="go">     4     2.511828e+00     5.237919e-01</span>
<span class="go">     5     2.107802e+00     1.020415e-01</span>
<span class="go">  0.009889 seconds (915 allocations: 270.266 KB)</span>
<span class="go">Results of Optimization Algorithm</span>
<span class="go"> * Algorithm: Gradient Descent</span>
<span class="go"> * Starting Point: [1.2,1.0, ...]</span>
<span class="go"> * Minimizer: [1.0287763814102757,1.05876866832087, ...]</span>
<span class="go"> * Minimum: 2.107802e+00</span>
<span class="go"> * Iterations: 5</span>
<span class="go"> * Convergence: false</span>
<span class="go">   * |x - x&#39;| &lt; 0.0: false</span>
<span class="go">   * |f(x) - f(x&#39;)| / |f(x)| &lt; 0.0: false</span>
<span class="go">   * |g(x)| &lt; 1.0e-08: false</span>
<span class="go">   * Reached Maximum Number of Iterations: true</span>
<span class="go"> * Objective Function Calls: 23</span>
<span class="go"> * Gradient Calls: 23</span>
</pre></div>


<p>The objective has obtained a value that is very similar between the two runs, but the run with the analytical gradient is way faster.  It is possible that the finite differences code can be improved, but generally the optimization will be slowed down by all the function evaluations required to do the central finite differences calculations.</p>
<p><a id='Separating-time-spent-in-Optim's-code-and-user-provided-functions-1'></a></p>
<h2 id="separating-time-spent-in-optims-code-and-user-provided-functions">Separating time spent in Optim's code and user provided functions</h2>
<p>Consider the Rosenbrock problem.</p>
<div class="codehilite"><pre><span></span><span class="k">using</span> <span class="n">Optim</span>
<span class="n">prob</span> <span class="o">=</span> <span class="n">Optim</span><span class="o">.</span><span class="n">UnconstrainedProblems</span><span class="o">.</span><span class="n">examples</span><span class="p">[</span><span class="s">&quot;Rosenbrock&quot;</span><span class="p">];</span>
</pre></div>


<p>Say we optimize this function, and look at the total run time of <code>optimize</code> using the Newton Trust Region method, and we are surprised that it takes a long time to run. We then wonder if time is spent in Optim's own code (solving the sub-problem for example) or in evaluating the objective, gradient or hessian that we provided. Then it can be very useful to use the <a href="https://github.com/KristofferC/TimerOutputs.jl">TimerOutputs.jl</a> package. This package allows us to run an over-all timer for <code>optimize</code>, and add individual timers for <code>f</code>, <code>g!</code>, and <code>h!</code>. Consider the example below, that is due to the author of the package (Kristoffer Carlsson).</p>
<div class="codehilite"><pre><span></span><span class="k">using</span> <span class="n">TimerOutputs</span>
<span class="kd">const</span> <span class="n">to</span> <span class="o">=</span> <span class="n">TimerOutput</span><span class="p">()</span>

<span class="n">f</span><span class="p">(</span><span class="n">x</span>    <span class="p">)</span> <span class="o">=</span>  <span class="nd">@timeit</span> <span class="n">to</span> <span class="s">&quot;f&quot;</span>  <span class="n">prob</span><span class="o">.</span><span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">g!</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">g</span><span class="p">)</span> <span class="o">=</span>  <span class="nd">@timeit</span> <span class="n">to</span> <span class="s">&quot;g!&quot;</span> <span class="n">prob</span><span class="o">.</span><span class="n">g!</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">g</span><span class="p">)</span>
<span class="n">h!</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span> <span class="o">=</span>  <span class="nd">@timeit</span> <span class="n">to</span> <span class="s">&quot;h!&quot;</span> <span class="n">prob</span><span class="o">.</span><span class="n">h!</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span>

<span class="k">begin</span>
<span class="n">reset_timer!</span><span class="p">(</span><span class="n">to</span><span class="p">)</span>
<span class="nd">@timeit</span> <span class="n">to</span> <span class="s">&quot;Trust Region&quot;</span> <span class="k">begin</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">Optim</span><span class="o">.</span><span class="n">optimize</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">g!</span><span class="p">,</span> <span class="n">h!</span><span class="p">,</span> <span class="n">prob</span><span class="o">.</span><span class="n">initial_x</span><span class="p">,</span> <span class="n">NewtonTrustRegion</span><span class="p">())</span>
<span class="k">end</span>
<span class="n">show</span><span class="p">(</span><span class="n">to</span><span class="p">;</span> <span class="n">allocations</span> <span class="o">=</span> <span class="kc">false</span><span class="p">)</span>
<span class="k">end</span>
</pre></div>


<p>We see that the time is actually <em>not</em> spent in our provided functions, but most of the time is spent in the code for the trust region method.</p>
<p><a id='Early-stopping-1'></a></p>
<h2 id="early-stopping">Early stopping</h2>
<p>Sometimes it might be of interest to stop the optimizer early. The simplest way to do this is to set the <code>iterations</code> keyword in <code>Optim.Options</code> to some number. This will prevent the iteration counter exceeding some limit, with the standard value being 1000. Alternatively, it is possible to put a soft limit on the run time of the optimization procedure by setting the <code>time_limit</code> keyword in the <code>Optim.Options</code> constructor.</p>
<div class="codehilite"><pre><span></span><span class="k">using</span> <span class="n">Optim</span>
<span class="n">problem</span> <span class="o">=</span> <span class="n">Optim</span><span class="o">.</span><span class="n">UnconstrainedProblems</span><span class="o">.</span><span class="n">examples</span><span class="p">[</span><span class="s">&quot;Rosenbrock&quot;</span><span class="p">]</span>

<span class="n">f</span> <span class="o">=</span> <span class="n">problem</span><span class="o">.</span><span class="n">f</span>
<span class="n">initial_x</span> <span class="o">=</span> <span class="n">problem</span><span class="o">.</span><span class="n">initial_x</span>

<span class="k">function</span> <span class="n">slow</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">sleep</span><span class="p">(</span><span class="mf">0.1</span><span class="p">)</span>
    <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="k">end</span>

<span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>

<span class="n">optimize</span><span class="p">(</span><span class="n">slow</span><span class="p">,</span> <span class="n">zeros</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="n">NelderMead</span><span class="p">(),</span> <span class="n">Optim</span><span class="o">.</span><span class="n">Options</span><span class="p">(</span><span class="n">time_limit</span> <span class="o">=</span> <span class="mf">3.0</span><span class="p">))</span>
</pre></div>


<p>This will stop after about three seconds. If it is more important that we stop before the limit is reached, it is possible to use a callback with a simple model for predicting how much time will have passed when the next iteration is over. Consider the following code</p>
<div class="codehilite"><pre><span></span><span class="k">using</span> <span class="n">Optim</span>
<span class="n">problem</span> <span class="o">=</span> <span class="n">Optim</span><span class="o">.</span><span class="n">UnconstrainedProblems</span><span class="o">.</span><span class="n">examples</span><span class="p">[</span><span class="s">&quot;Rosenbrock&quot;</span><span class="p">]</span>

<span class="n">f</span> <span class="o">=</span> <span class="n">problem</span><span class="o">.</span><span class="n">f</span>
<span class="n">initial_x</span> <span class="o">=</span> <span class="n">problem</span><span class="o">.</span><span class="n">initial_x</span>

<span class="k">function</span> <span class="n">very_slow</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">sleep</span><span class="p">(</span><span class="o">.</span><span class="mi">5</span><span class="p">)</span>
    <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="k">end</span>

<span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>
<span class="n">time_to_setup</span> <span class="o">=</span> <span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="k">function</span> <span class="n">advanced_time_control</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">println</span><span class="p">(</span><span class="s">&quot; * Iteration:       &quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">iteration</span><span class="p">)</span>
    <span class="n">so_far</span> <span class="o">=</span>  <span class="n">time</span><span class="p">()</span><span class="o">-</span><span class="n">start_time</span>
    <span class="n">println</span><span class="p">(</span><span class="s">&quot; * Time so far:     &quot;</span><span class="p">,</span> <span class="n">so_far</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">iteration</span> <span class="o">==</span> <span class="mi">0</span>
        <span class="n">time_to_setup</span><span class="p">[</span><span class="o">:</span><span class="p">]</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span><span class="o">-</span><span class="n">start_time</span>
    <span class="k">else</span>
        <span class="n">expected_next_time</span> <span class="o">=</span> <span class="n">so_far</span> <span class="o">+</span> <span class="p">(</span><span class="n">time</span><span class="p">()</span><span class="o">-</span><span class="n">start_time</span><span class="o">-</span><span class="n">time_to_setup</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="o">/</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">iteration</span><span class="p">)</span>
        <span class="n">println</span><span class="p">(</span><span class="s">&quot; * Next iteration ≈ &quot;</span><span class="p">,</span> <span class="n">expected_next_time</span><span class="p">)</span>
        <span class="n">println</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">expected_next_time</span> <span class="o">&lt;</span> <span class="mi">13</span> <span class="o">?</span> <span class="kc">false</span> <span class="o">:</span> <span class="kc">true</span>
    <span class="k">end</span>
    <span class="n">println</span><span class="p">()</span>
    <span class="kc">false</span>
<span class="k">end</span>
<span class="n">optimize</span><span class="p">(</span><span class="n">very_slow</span><span class="p">,</span> <span class="n">zeros</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="n">NelderMead</span><span class="p">(),</span> <span class="n">Optim</span><span class="o">.</span><span class="n">Options</span><span class="p">(</span><span class="n">callback</span> <span class="o">=</span> <span class="n">advanced_time_control</span><span class="p">))</span>
</pre></div>


<p>It will try to predict the elapsed time after the next iteration is over, and stop now if it is expected to exceed the limit of 13 seconds. Running it, we get something like the following output</p>
<div class="codehilite"><pre><span></span><span class="gp">julia&gt;</span> <span class="n">optimize</span><span class="p">(</span><span class="n">very_slow</span><span class="p">,</span> <span class="n">zeros</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="n">NelderMead</span><span class="p">(),</span> <span class="n">Optim</span><span class="o">.</span><span class="n">Options</span><span class="p">(</span><span class="n">callback</span> <span class="o">=</span> <span class="n">advanced_time_control</span><span class="p">))</span>
<span class="go"> * Iteration:       0</span>
<span class="go"> * Time so far:     2.219298839569092</span>

<span class="go"> * Iteration:       1</span>
<span class="go"> * Time so far:     3.4006409645080566</span>
<span class="go"> * Next iteration ≈ 4.5429909229278564</span>

<span class="go"> * Iteration:       2</span>
<span class="go"> * Time so far:     4.403923988342285</span>
<span class="go"> * Next iteration ≈ 5.476739525794983</span>

<span class="go"> * Iteration:       3</span>
<span class="go"> * Time so far:     5.407265901565552</span>
<span class="go"> * Next iteration ≈ 6.4569235642751055</span>

<span class="go"> * Iteration:       4</span>
<span class="go"> * Time so far:     5.909044027328491</span>
<span class="go"> * Next iteration ≈ 6.821732044219971</span>

<span class="go"> * Iteration:       5</span>
<span class="go"> * Time so far:     6.912338972091675</span>
<span class="go"> * Next iteration ≈ 7.843148183822632</span>

<span class="go"> * Iteration:       6</span>
<span class="go"> * Time so far:     7.9156060218811035</span>
<span class="go"> * Next iteration ≈ 8.85849153995514</span>

<span class="go"> * Iteration:       7</span>
<span class="go"> * Time so far:     8.918903827667236</span>
<span class="go"> * Next iteration ≈ 9.870419979095459</span>

<span class="go"> * Iteration:       8</span>
<span class="go"> * Time so far:     9.922197818756104</span>
<span class="go"> * Next iteration ≈ 10.880185931921005</span>

<span class="go"> * Iteration:       9</span>
<span class="go"> * Time so far:     10.925468921661377</span>
<span class="go"> * Next iteration ≈ 11.888488478130764</span>

<span class="go"> * Iteration:       10</span>
<span class="go"> * Time so far:     11.92870283126831</span>
<span class="go"> * Next iteration ≈ 12.895747828483582</span>

<span class="go"> * Iteration:       11</span>
<span class="go"> * Time so far:     12.932114839553833</span>
<span class="go"> * Next iteration ≈ 13.902462200684981</span>

<span class="go">Results of Optimization Algorithm</span>
<span class="go"> * Algorithm: Nelder-Mead</span>
<span class="go"> * Starting Point: [0.0,0.0]</span>
<span class="go"> * Minimizer: [0.23359374999999996,0.042187499999999996, ...]</span>
<span class="go"> * Minimum: 6.291677e-01</span>
<span class="go"> * Iterations: 11</span>
<span class="go"> * Convergence: false</span>
<span class="go">   *  √(Σ(yᵢ-ȳ)²)/n &lt; 1.0e-08: false</span>
<span class="go">   * Reached Maximum Number of Iterations: false</span>
<span class="go"> * Objective Function Calls: 24</span>
</pre></div>

  <br>
    

  <div class="row wm-article-nav-buttons" role="navigation" aria-label="navigation">
    
    <div class="wm-article-nav pull-right">
      <a href="../../algo/nelder_mead/" class="btn btn-xs btn-default pull-right">
        Next
        <i class="fa fa-chevron-right" aria-hidden="true"></i>
      </a>
      <a href="../../algo/nelder_mead/" class="btn btn-xs btn-link">
        Nelder Mead
      </a>
    </div>
    
    <div class="wm-article-nav">
      <a href="../config/" class="btn btn-xs btn-default pull-left">
        <i class="fa fa-chevron-left" aria-hidden="true"></i>
        Previous</a><a href="../config/" class="btn btn-xs btn-link">
        Configurable Options
      </a>
    </div>
    
  </div>

    <br>
</div>

<footer class="col-md-12 wm-page-content">
  <p>Documentation built with <a href="http://www.mkdocs.org/">MkDocs</a> using <a href="https://github.com/gristlabs/mkdocs-windmill">Windmill</a> theme by Grist Labs.</p>
</footer>

</body>
</html>